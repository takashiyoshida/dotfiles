#!/usr/bin/env python

import argparse
import csv
import logging
import logging.handlers
import multiprocessing
import os
import re
import shutil
import subprocess
import tempfile
from time import time


HOSTNAME = r'[a-z]{3}rtu[12]'
MACHINE_NUM = r'rt[su][12]'

YEAR = r'\d{4}'
MONTH = r'[01]\d'
DAY = r'[0-3]\d'

HOUR = r'[0-2]\d'
MINUTE = r'[0-5]\d'
SECOND = r'[0-5]\d'
MSECOND = r'\d{3}'

TIMESTAMP = r'(?P<timestamp>%s-%s-%s %s:%s:%s\.%s)' % (YEAR, MONTH, DAY, HOUR, MINUTE,
                                                       SECOND, MSECOND)
HOSTNAME = r'(?P<host>[a-z]{3}rt[su][12]) '
LEVEL = r'(?P<level>[a-z0-9]+):'
PROCESS = r'(?P<process>nelrtuapp_[a-z]{3})\[(?P<process_id>\d+)\]:'

# <filename>:?(?<line number>)?:?
FILENAME1 = r'(?P<filename>[\w\-]+\.[a-z]+):?\(?(?P<line>\d+)\)?:?'
# <filename>:<function name:ignored>(<line number>):
FILENAME2 = r'(?P<filename>[\w\-]+\.[a-z]+):\w+[:\(]?(?P<line>\d+)\)?:?'
# <function name:ignored> - <filename>(<line number>)
FILENAME3 = r'.+ - (?P<filename>[\w\-\/]+\.[a-z]+)\((?P<line>\d+)\)'

USER_ACTION = r'(?P<user>[a-z]+):'


class CookieJar:
    def __init__(self):
        self._cookie_jar_file = '%s/.danzig' % (os.environ['HOME'])
        self._jar = []
        self.load_cookies()

    def load_cookies(self):
        try:
            with open(self._cookie_jar_file, 'r') as cookie_jar:
                for cookie in cookie_jar:
                    self._jar.append(cookie)
        except:
            pass

    def is_inside(self, root, file):
        cookie = '%s/%s' % (root, file)
        return cookie in self._jar

    def store_cookie(self, root, file):
        if not self.is_inside(root, file):
            cookie = '%s/%s' % (root, file)
            self._jar.append(cookie)
            with open(self._cookie_jar_file, 'w+') as cookie_jar:
                cookie_jar.write(cookie)


_jar = CookieJar()


def init_logging():
    '''
    Initializes logger
    '''
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    console = logging.StreamHandler()
    cons_formatter = logging.Formatter(fmt='%(levelname)s %(message)s')
    console.setFormatter(cons_formatter)
    console.setLevel(logging.INFO)

    f = logging.FileHandler('danzig.log')
    f_formatter = logging.Formatter(
        fmt='%(asctime)s %(levelname)s %(message)s')
    f.setFormatter(f_formatter)
    f.setLevel(logging.DEBUG)

    logger.addHandler(console)
    logger.addHandler(f)
    return logger


def uncompress_zip(zipfile, destination):
    '''
    Performs a unzip on the given file
    '''
    logging.debug('Uncompressing a Zip file, %s to %s', zipfile, destination)
    return subprocess.call(['/usr/bin/unzip', zipfile, '-d', destination])


def uncompress_7zip(zipfile, destination):
    logging.debug('Uncompressing a 7zip file, %s to %s', zipfile, destination)
    return subprocess.call(['/usr/bin/7z', 'e', '-o%s' % (destination), zipfile])


def uncompress_gzip(zipfile, destination):
    logging.debug('Uncompressing a Gzip file, %s to %s', zipfile, destination)
    return subprocess.call(['/bin/gunzip'])


def uncompress_tar(tarfile, destination):
    logging.debug('Uncompressing a Tar file, %s to %s', tarfile, destination)
    return subprocess.call(['/bin/tar', 'xzf', tarfile, '-C', destination])


def uncompress_nelrtu_logs(directory):
    '''
    Uncompress archived NELRTU logs from a given directory
    '''
    logfiles = []
    for root, _, files in os.walk(directory):
        for file in files:
            filename, extension = os.path.splitext(file)
            if file.startswith('nelrtu.log'):
                if extension == '.gz':
                    gzipfile = '%s/%s' % (root, file)
                    logging.debug('Expanding %s ...', gzipfile)
                    result = subprocess.call(['/bin/gunzip', gzipfile])
                    if result == 0:
                        logfiles.append('%s/%s' % (root, filename))
                    else:
                        logging.error('Failed to expand %s', gzipfile)
                else:
                    logfiles.append('%s/%s' % (root, file))
            else:
                logging.debug(
                    'Found non-NELRTU log file, %s, skipping...', file)
    return logfiles


def purify_text(text):
    '''
    Remove non-ASCII characters from text
    '''
    cleaned = (c for c in text if 0 < ord(c) < 127)
    return ''.join(cleaned).strip()


def convert_level_num_to_level_name(text):
    '''
    '''
    levels = {0: 'emerg',
              1: 'alert',
              2: 'crit',
              3: 'err',
              4: 'warning',
              5: 'notice',
              6: 'info',
              7: 'debug'}
    try:
        num = int(text)
        if 0 < num > 7:
            text = 'unknown'
        else:
            text = levels[num]
    except:
        # the text is already a level name, not a level number
        pass
    return text


def process_nelrtu_log(infile, hostname='unknown'):
    '''
    Parses a given NELRTU log file and returns a list of events contained
    in the log file.
    - DEBUG level events are ignored
    - Hexdump events are also ignored
    '''
    events = []

    with open(infile, 'r') as logfile:
        t0 = time()
        count = 0

        for line in logfile:
            count = count + 1
            line = purify_text(line)

            match = re.match(TIMESTAMP, line)
            if match:
                event = {'timestamp': '',
                         'host': hostname,  # use default hostname, first
                         'level': '',
                         'process': '',
                         'process_id': '',
                         'filename': '',
                         'line': '',
                         'user': '',
                         'message': ''}

                event['timestamp'] = match.group('timestamp')
                line = line[match.end():].strip()

                match = re.match(HOSTNAME, line)
                if match:
                    event['host'] = match.group('host')
                    line = line[match.end():].strip()

                match = re.match(LEVEL, line)
                if match:
                    event['level'] = convert_level_num_to_level_name(
                        match.group('level'))
                    line = line[match.end():].strip()

                    match = re.match(PROCESS, line)
                    if match:
                        event['process'] = match.group('process')
                        event['process_id'] = match.group('process_id')
                        line = line[match.end():].strip()

                        match = re.match(FILENAME1, line)
                        if match:
                            event['filename'] = match.group('filename')
                            event['line'] = match.group('line')
                            event['message'] = line[match.end():].strip()
                        else:
                            match = re.match(FILENAME2, line)
                            if match:
                                event['filename'] = match.group('filename')
                                event['line'] = match.group('line')
                                event['message'] = line[match.end():].strip()
                            else:
                                match = re.match(FILENAME3, line)
                                if match:
                                    event['filename'] = match.group('filename')
                                    event['line'] = match.group('line')
                                    event['message'] = line[match.end():].strip()
                                else:
                                    event['message'] = line.strip()
                    else:
                        match = re.match(USER_ACTION, line)
                        if match:
                            event['user'] = match.group('user')
                            event['message'] = line[match.end():].strip()
                        else:
                            logging.error('Unable to match process name and ID in %s at %d',
                                          infile, count)
                            logging.error(line)
                else:
                    logging.error(
                        'Unable to match log level in %s at %d', infile, count)
                    logging.error(line)

                if event['level'] == 'debug':
                    continue

                # Only keep the SWC log with 0x000000: otherwise, drop all other SWC log
                if event['message'].find('0x') != -1 and event['message'].find('0x000000') == -1:
                    continue

                logging.debug('timestamp: %s', event['timestamp'])
                logging.debug('host: %s', event['host'])
                logging.debug('level: %s', event['level'])
                logging.debug('process: %s', event['process'])
                logging.debug('process id: %s', event['process_id']),
                logging.debug('filename: %s', event['filename']),
                logging.debug('line: %s', event['line'])
                logging.debug('user: %s', event['user'])
                logging.debug('message: %s', event['message'])

                events.append(event)
            else:
                logging.error(
                    'Unable to match timestamp in %s at %d', infile, count)
                logging.error(line)

        t1 = time()
        logging.info('Extracted %d events from %s, took %.3f seconds',
                     len(events), infile, t1 - t0)
    return events


def write_events_to_csv(outfile, events):
    '''
    Writes a list of events to a CSV file
    '''
    with open(outfile, 'w') as csvfile:
        fieldnames = ['timestamp', 'host', 'level', 'process', 'process_id',
                      'filename', 'line', 'message']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        for event in events:
            writer.writerow({'timestamp': event['timestamp'],
                             'host': event['host'],
                             'level': event['level'],
                             'process': event['process'],
                             'process_id': event['process_id'],
                             'filename': event['filename'],
                             'line': event['line'],
                             'message': event['message']})


def write_to_cookie(root, file):
    cookie_file = '%s/.danzig' % (os.environ['HOME'])
    with open(cookie_file, 'w+') as cookie:
        cookie.write('%s/%s' % (root, file))


def cleanup(directory, keep_flag=False):
    '''
    Remove a given directory
    '''
    if keep_flag:
        logging.info('Leaving the directory, %s, untouched...', directory)
    else:
        logging.info('Removing the directory, %s ...', directory)
        shutil.rmtree(directory)


def do_work(root, file, dry_run=False, keep=False):
    '''
    '''
    tempdir = tempfile.mkdtemp()
    filename, extension = os.path.splitext(file)

    if not _jar.is_inside(root, file):
        result = -1

        if extension.lower() == '.zip':
            result = uncompress_zip(
                '%s/%s' % (root, file), '%s/logs' % (tempdir))
        elif extension.lower() == '.gz':
            result = uncompress_tar('%s/%s' % (root, file), tempdir)
        elif extension.lower() == '.7z':
            result = uncompress_7zip(
                '%s/%s' % (root, file), '%s/logs' % (tempdir))
        else:
            logging.warning('Found unknown file type, %s, skipping', file)

        if result == 0:
            logfiles = uncompress_nelrtu_logs('%s/logs' % (tempdir))
            if not dry_run:
                logging.debug('logfiles: %s', logfiles)
                events = []
                for log in logfiles:
                    events.extend(process_nelrtu_log(log))
                logging.info('Total number of events: %d', len(events))
                if len(events) > 0:
                    basename = os.path.basname(root)
                    write_events_to_csv('%s-%s.csv' %
                                        (basename, filename), events)
                # write to a cookie file
                _jar.store_cookie(root, file)
        cleanup(tempdir, keep)


def main():
    '''
    main function
    '''
    init_logging()

    parser = argparse.ArgumentParser(prog='danzig')
    parser.add_argument('--directory', '-d', required=True,
                        dest='directory', help='path to NELRTU log directory')
    parser.add_argument('--dry-run', '-r', required=False, action='store_true',
                        default=False, dest='dry_run',
                        help='Traverses the given directory, but does not process the discovered NELRTU log files')
    parser.add_argument('--keep', '-k', required=False, action='store_true',
                        default=False, dest='keep',
                        help='keep temporary files (for debugging)')
    parser.add_argument('--pool', '-p', required=False, type=int, default=1, dest='pool',
                        help='Number of worker processes to be used')
    args = parser.parse_args()

    pool = multiprocessing.Pool(args.pool)
    for root, _, files in os.walk(args.directory):
        for file in files:
            pool.apply_async(do_work, [root, file, args.dry_run, args.keep])

    pool.close()
    pool.join()


if __name__ == "__main__":
    main()
